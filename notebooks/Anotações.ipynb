{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "60dd72c1-8198-4129-ac23-27ae3313e2b3",
   "metadata": {},
   "source": [
    "# <font color='red'>1) Getting Started With Pandas</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e56f2a58-b313-4135-9a3a-5b5bdd77d156",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "\n",
    "## <font color='blue'>Anatomia de um DataFrame</font>\n",
    "Um __DataFrame__ é composto por uma ou mais __Series__. Os nomes das series formam os nomes das __colunas__ e os rótulos das linhas formam o __Index__."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ebfbb38-14ae-4d37-8dfb-7f7f2f13a695",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>id</th>\n",
       "      <th>nametype</th>\n",
       "      <th>recclass</th>\n",
       "      <th>mass (g)</th>\n",
       "      <th>fall</th>\n",
       "      <th>year</th>\n",
       "      <th>reclat</th>\n",
       "      <th>reclong</th>\n",
       "      <th>GeoLocation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aachen</td>\n",
       "      <td>1</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L5</td>\n",
       "      <td>21</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1880 12:00:00 AM</td>\n",
       "      <td>50.77500</td>\n",
       "      <td>6.08333</td>\n",
       "      <td>(50.775, 6.08333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aarhus</td>\n",
       "      <td>2</td>\n",
       "      <td>Valid</td>\n",
       "      <td>H6</td>\n",
       "      <td>720</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1951 12:00:00 AM</td>\n",
       "      <td>56.18333</td>\n",
       "      <td>10.23333</td>\n",
       "      <td>(56.18333, 10.23333)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Abee</td>\n",
       "      <td>6</td>\n",
       "      <td>Valid</td>\n",
       "      <td>EH4</td>\n",
       "      <td>107000</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1952 12:00:00 AM</td>\n",
       "      <td>54.21667</td>\n",
       "      <td>-113.00000</td>\n",
       "      <td>(54.21667, -113.0)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Acapulco</td>\n",
       "      <td>10</td>\n",
       "      <td>Valid</td>\n",
       "      <td>Acapulcoite</td>\n",
       "      <td>1914</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1976 12:00:00 AM</td>\n",
       "      <td>16.88333</td>\n",
       "      <td>-99.90000</td>\n",
       "      <td>(16.88333, -99.9)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Achiras</td>\n",
       "      <td>370</td>\n",
       "      <td>Valid</td>\n",
       "      <td>L6</td>\n",
       "      <td>780</td>\n",
       "      <td>Fell</td>\n",
       "      <td>01/01/1902 12:00:00 AM</td>\n",
       "      <td>-33.16667</td>\n",
       "      <td>-64.95000</td>\n",
       "      <td>(-33.16667, -64.95)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       name   id nametype     recclass  mass (g)  fall   \n",
       "0    Aachen    1    Valid           L5        21  Fell  \\\n",
       "1    Aarhus    2    Valid           H6       720  Fell   \n",
       "2      Abee    6    Valid          EH4    107000  Fell   \n",
       "3  Acapulco   10    Valid  Acapulcoite      1914  Fell   \n",
       "4   Achiras  370    Valid           L6       780  Fell   \n",
       "\n",
       "                     year    reclat    reclong           GeoLocation  \n",
       "0  01/01/1880 12:00:00 AM  50.77500    6.08333     (50.775, 6.08333)  \n",
       "1  01/01/1951 12:00:00 AM  56.18333   10.23333  (56.18333, 10.23333)  \n",
       "2  01/01/1952 12:00:00 AM  54.21667 -113.00000    (54.21667, -113.0)  \n",
       "3  01/01/1976 12:00:00 AM  16.88333  -99.90000     (16.88333, -99.9)  \n",
       "4  01/01/1902 12:00:00 AM -33.16667  -64.95000   (-33.16667, -64.95)  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#Vizualização menor com rows = 5\n",
    "meteoritos = pd.read_csv('/home/nicolas.fs/Estudos-PIBE/Repositório-GIT/pandas-workshop/data/Meteorite_Landings.csv', nrows=5)\n",
    "#Vizualização completa\n",
    "meteorites = pd.read_csv('/home/nicolas.fs/Estudos-PIBE/Repositório-GIT/pandas-workshop/data/Meteorite_Landings.csv')\n",
    "\n",
    "meteoritos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e98ed0c2-055b-43d1-aac2-f06fbb7e103d",
   "metadata": {},
   "source": [
    "Este comando acaba de utilizar o módulo __pandas__ para fazer a criação da tabela de Meteoritos utilizando o comando __pd.read_csv__. Com isso podemos fazer algumas análises utilizando a variável meteoritos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9294b309-f374-4752-843d-795a8de962c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      Aachen\n",
       "1      Aarhus\n",
       "2        Abee\n",
       "3    Acapulco\n",
       "4     Achiras\n",
       "Name: name, dtype: object"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteoritos.name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1cc1a72c-7325-4383-ac64-440a1b267150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['name', 'id', 'nametype', 'recclass', 'mass (g)', 'fall', 'year',\n",
       "       'reclat', 'reclong', 'GeoLocation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteoritos.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8d8e5de0-8b6c-4ee4-a86e-ee7361cefe7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=5, step=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meteoritos.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb2591a9-27b8-4707-916e-2685cb083da6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <font color='blue'>Criando DataFrames</font>\n",
    "Podemos criar DataFrames a partir de uma variedade de fontes, como outros __objetos Python__. Veremos apenas alguns exemplos, mas podemos conferir a página da documentação para obter uma lista completa."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff34ae42-8a82-448b-b1ee-7b213b98a520",
   "metadata": {},
   "source": [
    "### Usando apenas uma linha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b00c1ae-ed3d-4eb5-9cae-839c36bbd4d2",
   "metadata": {},
   "source": [
    "Do mesmo formato no qual fizemos anteriormente, utilizando o comando __pd.read__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356919f6-0352-48b9-a4bb-1fe35b5d25d9",
   "metadata": {},
   "source": [
    "### Usando dados de uma API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "522ee55d-e96c-48de-8cbc-d85452d26da2",
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectionError",
     "evalue": "HTTPSConnectionPool(host='data.nasa.gov', port=443): Max retries exceeded with url: /resource/gh4g-9sfh.json?%24limit=50000 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f890e205be0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:159\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 159\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dns_host\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mport\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mextra_kw\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py:84\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m socket\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgetaddrinfo returns an empty list\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/connection.py:74\u001b[0m, in \u001b[0;36mcreate_connection\u001b[0;34m(address, timeout, source_address, socket_options)\u001b[0m\n\u001b[1;32m     73\u001b[0m     sock\u001b[38;5;241m.\u001b[39mbind(source_address)\n\u001b[0;32m---> 74\u001b[0m \u001b[43msock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43msa\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m sock\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 101] Network is unreachable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNewConnectionError\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:666\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    665\u001b[0m \u001b[38;5;66;03m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[0;32m--> 666\u001b[0m httplib_response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    667\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[38;5;66;03m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[1;32m    677\u001b[0m \u001b[38;5;66;03m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[1;32m    678\u001b[0m \u001b[38;5;66;03m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[1;32m    679\u001b[0m \u001b[38;5;66;03m# mess.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:377\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[0;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 377\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;66;03m# Py2 raises this as a BaseSSLError, Py3 raises it as socket timeout.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:1001\u001b[0m, in \u001b[0;36mHTTPSConnectionPool._validate_conn\u001b[0;34m(self, conn)\u001b[0m\n\u001b[1;32m   1000\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(conn, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msock\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):  \u001b[38;5;66;03m# AppEngine might not have  `.sock`\u001b[39;00m\n\u001b[0;32m-> 1001\u001b[0m     \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1003\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m conn\u001b[38;5;241m.\u001b[39mis_verified:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:314\u001b[0m, in \u001b[0;36mVerifiedHTTPSConnection.connect\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconnect\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    313\u001b[0m     \u001b[38;5;66;03m# Add certificate verification\u001b[39;00m\n\u001b[0;32m--> 314\u001b[0m     conn \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_new_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    315\u001b[0m     hostname \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhost\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connection.py:171\u001b[0m, in \u001b[0;36mHTTPConnection._new_conn\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m SocketError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m--> 171\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NewConnectionError(\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to establish a new connection: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m e\n\u001b[1;32m    173\u001b[0m     )\n\u001b[1;32m    175\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m conn\n",
      "\u001b[0;31mNewConnectionError\u001b[0m: <urllib3.connection.VerifiedHTTPSConnection object at 0x7f890e205be0>: Failed to establish a new connection: [Errno 101] Network is unreachable",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMaxRetryError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/adapters.py:667\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    666\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 667\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[43mconn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    677\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    678\u001b[0m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    679\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    681\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/connectionpool.py:720\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[0;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[1;32m    718\u001b[0m     e \u001b[38;5;241m=\u001b[39m ProtocolError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConnection aborted.\u001b[39m\u001b[38;5;124m\"\u001b[39m, e)\n\u001b[0;32m--> 720\u001b[0m retries \u001b[38;5;241m=\u001b[39m \u001b[43mretries\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    722\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    723\u001b[0m retries\u001b[38;5;241m.\u001b[39msleep()\n",
      "File \u001b[0;32m/usr/lib/python3/dist-packages/urllib3/util/retry.py:436\u001b[0m, in \u001b[0;36mRetry.increment\u001b[0;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m new_retry\u001b[38;5;241m.\u001b[39mis_exhausted():\n\u001b[0;32m--> 436\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause))\n\u001b[1;32m    438\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIncremented Retry for (url=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m\"\u001b[39m, url, new_retry)\n",
      "\u001b[0;31mMaxRetryError\u001b[0m: HTTPSConnectionPool(host='data.nasa.gov', port=443): Max retries exceeded with url: /resource/gh4g-9sfh.json?%24limit=50000 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f890e205be0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mrequests\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mrequests\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhttps://data.nasa.gov/resource/gh4g-9sfh.json\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m$limit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m50_000\u001b[39;49m\u001b[43m}\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mok:\n\u001b[1;32m      9\u001b[0m     payload \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/api.py:73\u001b[0m, in \u001b[0;36mget\u001b[0;34m(url, params, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget\u001b[39m(url, params\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     63\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[38;5;124;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 73\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mget\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/api.py:59\u001b[0m, in \u001b[0;36mrequest\u001b[0;34m(method, url, **kwargs)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m sessions\u001b[38;5;241m.\u001b[39mSession() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[0;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[1;32m    584\u001b[0m send_kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    585\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m\"\u001b[39m: timeout,\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow_redirects\u001b[39m\u001b[38;5;124m\"\u001b[39m: allow_redirects,\n\u001b[1;32m    587\u001b[0m }\n\u001b[1;32m    588\u001b[0m send_kwargs\u001b[38;5;241m.\u001b[39mupdate(settings)\n\u001b[0;32m--> 589\u001b[0m resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[0;34m(self, request, **kwargs)\u001b[0m\n\u001b[1;32m    700\u001b[0m start \u001b[38;5;241m=\u001b[39m preferred_clock()\n\u001b[1;32m    702\u001b[0m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[0;32m--> 703\u001b[0m r \u001b[38;5;241m=\u001b[39m \u001b[43madapter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[1;32m    706\u001b[0m elapsed \u001b[38;5;241m=\u001b[39m preferred_clock() \u001b[38;5;241m-\u001b[39m start\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/requests/adapters.py:700\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[0;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[1;32m    696\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e\u001b[38;5;241m.\u001b[39mreason, _SSLError):\n\u001b[1;32m    697\u001b[0m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[1;32m    698\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[0;32m--> 700\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request\u001b[38;5;241m=\u001b[39mrequest)\n",
      "\u001b[0;31mConnectionError\u001b[0m: HTTPSConnectionPool(host='data.nasa.gov', port=443): Max retries exceeded with url: /resource/gh4g-9sfh.json?%24limit=50000 (Caused by NewConnectionError('<urllib3.connection.VerifiedHTTPSConnection object at 0x7f890e205be0>: Failed to establish a new connection: [Errno 101] Network is unreachable'))"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "response = requests.get(\n",
    "    'https://data.nasa.gov/resource/gh4g-9sfh.json',\n",
    "    params={'$limit': 50_000}\n",
    ")\n",
    "\n",
    "if response.ok:\n",
    "    payload = response.json()\n",
    "else:\n",
    "    print(f'Request was not successful and returned code: {response.status_code}.')\n",
    "    payload = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b79dad3-d905-4da7-9e28-a19f65cd0231",
   "metadata": {},
   "source": [
    "Esse código está utilizando a biblioteca __requests__ para fazer uma solicitação __GET__ a uma API da NASA, pedindo um parâmetro com um __limite__ de __50.000__ registros. Se a resposta for bem-sucedida (status OK), os dados JSON são __armazenados em payload__; caso contrário, uma mensagem de erro é exibida e payload é __definido como None__.\n",
    "\n",
    "Criaremos agora o DataFrame com os resultados de payload, sendo o comando __df.head(n)__ responsável pelo __número de rows__ que teremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed77b84-a7c4-4a74-adc0-8660351f244c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(payload)\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8af6fcf2-58ff-4741-8e80-9075f69556aa",
   "metadata": {},
   "source": [
    "## <font color='blue'>Inspecionando dados</font>\n",
    "Agora que temos alguns dados, precisamos realizar uma inspeção inicial deles. Isso nos dá informações sobre a aparência dos dados, quantas linhas/colunas existem e quantos dados temos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60ebd217-707e-45ea-aea7-b8b7ed1877d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Verificação da quantidade de rows e colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76db8d68-efb8-498a-91a1-2fd56aafdd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39122d1e-ed43-4a62-9439-c93f255ade79",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Verificação do nome das colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954a1b1e-8772-4fd9-982c-9ebf1e9740ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "091c474a-6735-4f98-8b25-44ac78135987",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Verificação do tipo de dado que cada coluna informa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3b065c-431d-46cc-9331-106eb391230f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c044e302-7382-424a-bcad-007a19fca773",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Vizualização dos primeiros e últimos row de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a17fdf8-7a87-4de4-9d1f-c78ce23bdf96",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68f2c10-3111-4e96-aa45-a3a9e944e8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4445ee7-6fee-49a7-8b27-b384ae3a8c78",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pegando informações"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97da635-a077-4f62-b4e4-5c02c34e5e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b65f80-8bef-43f7-af1f-02bea3604c6e",
   "metadata": {},
   "source": [
    "## <font color='blue'>Extraindo subconjuntos</font>\n",
    "Uma parte crucial do trabalho com DataFrames é extrair subconjuntos de dados: encontrar linhas que atendam a um determinado conjunto de critérios, isolar colunas elinhas de interesse, etc. Esta seção será muito importante para muitas tarefas de análise."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eee0a61-a4b8-4a5f-b8cc-4f5f8c71473d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Selecionando colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7d5f885-3f7d-438f-b805-679a0fabd61f",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e1bb71-7dc8-4d4c-b955-1181f2fd5022",
   "metadata": {},
   "source": [
    "Podemos selecionar múltiplas colunas de uma vez:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d86e50d-b288-4158-9bef-b161241688b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites[['name','mass (g)']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "293a4414-83f3-485a-89f6-d28c93b139ee",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Selecionando linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5118f4c2-0262-4ced-a470-06a933373e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites[100:104]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63af1f9-ea81-4a9d-b691-04421875ead9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Indexando\n",
    "Usamos __iloc[]__ para selecionar linhas e colunas por suas posições"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cf1291-b9ea-44f4-86d3-73b96ad48caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.iloc[100:104,[0,3,4,6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc23108d-7bd1-44c5-bb08-ead0526a241b",
   "metadata": {},
   "source": [
    "E usamos __loc[]__ para selecionar por nome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9126f908-b0d8-4c2a-ad6b-0d8cb19fd9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.loc[100:104, 'mass (g)':'year']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588cbe11-7bda-4d23-a6e4-d2081f05aa1f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Filtros com máscaras booleanas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44817b41-9b06-4afa-9b83-451796d9bd2b",
   "metadata": {},
   "source": [
    "Uma máscara booleana é uma estrutura semelhante a um array de valores booleanos – é uma forma de __especificar__ quais linhas/colunas queremos __selecionar (True)__ e quais __não queremos (False)__."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceea2655-837e-43dd-99a3-6ba93c5bb7e2",
   "metadata": {},
   "source": [
    "Aqui está um exemplo de uma máscara booleana para meteoritos pesando mais de 50 gramas e que foram encontrados na Terra (podemos também identificar duas formas de fazer esta análise):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f6825c-24c6-4408-8ce0-b986207ca08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "(meteorites['mass (g)'] > 50) & (meteorites.fall == 'Found')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782729aa-3969-4ca4-9ce5-0c2a9d5b8686",
   "metadata": {},
   "source": [
    "Um meio alternativo é usar o comando `query()` (tomar cuidado para utilizar os caracteres especiais corretamente):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ab4adc7-adda-46c7-91cc-f6def2cf4727",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.query(\"`mass (g)` > 1e6 and fall == 'Fell'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b389a9e3-4fb8-4018-966e-6c08435d0fb8",
   "metadata": {},
   "source": [
    "## <font color='blue'>Calculando estatísticas resumidas</font>\n",
    "Na próxima seção, discutiremos a limpeza de dados para uma análise mais significativa de nossos conjuntos de dados; no entanto, já podemos extrair alguns insights interessantes dos dados dos meteoritos calculando estatísticas resumidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba240d32-38f8-4e04-ba9f-6021f58e94a6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Um parâmetro x outro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a817f0e-5f23-4d56-876b-b853783a8912",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.fall.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be043ac0-2b26-4133-99f1-0d58018aa939",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Qual é a massa do meteorito médio?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c356778-9a54-4a18-8ff8-4ec4b0b164cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites['mass (g)'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db3f8da-2fb8-4ce9-aabb-371718c84a17",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Analisando médias e quantis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec949baf-4f6e-4520-8f34-990d5fe4e165",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites['mass (g)'].quantile([0.01, 0.05, 0.5, 0.95, 0.99])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4da4672-b1ff-402e-bb37-706827dc8c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites['mass (g)'].median()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ac6cded-f8cb-4c2f-8201-08d7d43719e7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Qual é o meteorito mais pesado e o mais leve\n",
    "E como __mostrá-los__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38884e7f-a552-4ffa-bede-208eb3dde534",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites['mass (g)'].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e833da-dfb3-4e20-a263-b6f9c5e2f857",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Formato padrão de filtro para mostrara apenas os elementos filtrados com a condição booleana que queremos\n",
    "meteorites[meteorites['mass (g)'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deaf6163-4058-4ce2-9827-88a72c766c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites['mass (g)'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9681541b-e63d-4328-afd5-f67ba5ad006b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Maior = meteorites[meteorites['mass (g)'] == 60000000.0]\n",
    "Maior"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a047843-4275-4fe1-ae7a-723e5f25a6a3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Extraindo informações de um meteorito específico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb6e6877-9269-47d3-82e1-8f121f3adf0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.loc[meteorites['mass (g)'].idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f01d31f-ca5f-4c0f-9a71-404354cee36b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Quantos tipos diferentes de classes de meteoritos estão representados neste conjunto de dados?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd40905-70d2-4d13-b230-d696486460f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.recclass.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18f6930-1e2e-40fb-9fb1-edfa647ed6c4",
   "metadata": {},
   "source": [
    "Como por exemplo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584e3bb8-9a97-4b3a-a530-a68f2ba1c58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.recclass.unique()[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681afbcf-4d77-4413-9a5e-2e1dc4af51d4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Obtendo algumas estatísticas resumidas sobre os próprios dados\n",
    "Podemos obter estatísticas resumidas comuns para todas as colunas de uma só vez. Por padrão, serão apenas colunas numéricas, mas aqui resumiremos tudo junto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfad684e-ebaf-487c-9d76-44b839c15cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorites.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9a80956-ba6d-460f-85f8-831d54c72983",
   "metadata": {},
   "source": [
    "Valores NaN significam __dados ausentes__. Por exemplo, a coluna de queda contém __strings__, portanto não há valor para __média__; da mesma forma, a massa (g) é numérica, portanto não temos entradas para as estatísticas de resumo categóricas (única, superior, frequência)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1313e65-2ab1-4d19-94f3-77552c3d2931",
   "metadata": {},
   "source": [
    "# <font color='red'>2) Data Wrangling</font>\n",
    "\n",
    "Para preparar nossos dados para análise, precisamos realizar a __Data Wrangling__. Nesta seção, aprenderemos como limpar e reformatar dados (por exemplo: renomear colunas e corrigir incompatibilidades de tipos de dados), reestruturá-los/remodelá-los e enriquecê-los (por exemplo: discretizar colunas, calcular agregações e combinar fontes de dados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0316e6a5-fe78-433f-a6a0-7f06302f21e0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <font color='blue'>Limpeza de dados</font>\n",
    "Nesta seção, veremos como: criar renomear e eliminar colunas; conversão de tipo; e classificação. Trabalharemos com os dados de viagem de táxi de 2019 fornecidos pela NYC Open Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9aebe44-ee98-49f9-96d3-cf2da00448c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "taxis = pd.read_csv('../data/2019_Yellow_Taxi_Trip_Data.csv')\n",
    "taxis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e104e29b-6a59-483c-befb-2b2e36aeb75f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Descartando colunas\n",
    "Iremos utilizar como exemplo a coluna __store_and_fwd_flag__ e as colunas de ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95edd101-10c2-4522-b81e-3e9f9c5940ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = taxis.columns.str.contains('id$|store_and_fwd_flag', regex=True)\n",
    "columns_to_drop = taxis.columns[mask]\n",
    "columns_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d47e2a-e15d-4ffa-a72d-71033fbc6528",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = taxis.drop(columns=columns_to_drop)\n",
    "taxis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "face201d-104f-47cb-ad68-ccb486522e95",
   "metadata": {},
   "source": [
    "Criamos uma mascara chamada __mask__ utilizando os comandos e selecionando apenas as colunas que queriamos descartar. Após isso salvamos em `columns_to_drop` para depois assumir que __columns=columns_to_drop__ utilizando o comando `drop` para descartar as colunas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "534d4a46-2a29-4548-bc56-c1100f955839",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Renomeando colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b003f12-9daf-4fe5-8984-2cff3d1e78db",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = taxis.rename(\n",
    "    columns={\n",
    "        'tpep_pickup_datetime': 'pickup', \n",
    "        'tpep_dropoff_datetime': 'dropoff'\n",
    "    }\n",
    ")\n",
    "taxis.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4076ca-9133-42e6-b673-aafb52b8c575",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Convertendo tipos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0c6692-3db3-4f52-b8fa-1287b8187b14",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0567ed9a-32b4-43a1-861c-4a150fef49a0",
   "metadata": {},
   "source": [
    "Neste caso, queremos que __pickup__ e __dropoff__ sejam __datetimes__. Podemos arrumar isto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b1f64b7-4bcb-4116-88ca-f2ca1edff858",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis[['pickup', 'dropoff']] = \\\n",
    "    taxis[['pickup', 'dropoff']].apply(pd.to_datetime)\n",
    "taxis.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a67e2ce-cae9-43c8-85da-bad1a4174a1d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Criando novas colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb05b792-5351-48d0-9412-1e6969f2a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = taxis.assign(\n",
    "    elapsed_time=lambda x: x.dropoff - x.pickup, # 1\n",
    "    cost_before_tip=lambda x: x.total_amount - x.tip_amount,\n",
    "    tip_pct=lambda x: x.tip_amount / x.cost_before_tip, # 2\n",
    "    fees=lambda x: x.cost_before_tip - x.fare_amount, # 3\n",
    "    avg_speed=lambda x: x.trip_distance.div(\n",
    "        x.elapsed_time.dt.total_seconds() / 60 / 60\n",
    "    ) # 4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad4e414-01f2-4c47-afb3-05df4b59c149",
   "metadata": {},
   "source": [
    "Essas __funções lambdas__ são funções pequenas e anônimas que podem receber vários argumentos, mas só podem conter uma expressão (o valor de retorno).\n",
    "\n",
    "No caso temos algo do tipo:\n",
    "\n",
    "`coluna_nova = lambda x: x.coluna1 operação x.coluna2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cb84ee6-b150-465c-be8b-2a9dcf4929b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb413a29-a28d-4521-81df-bd3f23b045f7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Ordenando por valores\n",
    "Podemos usar o método `sort_values()` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c90417a-f2b4-4101-a2ef-9225756e5cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.sort_values(['passenger_count', 'pickup'], ascending=[False, True]).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab27cd1-919f-41c2-b73d-ac0012fa0c9a",
   "metadata": {},
   "source": [
    "Para escolher as linhas maiores e menores, usamos `nlargest()` e `nsmallest()`. Vejamos um exemplo olhando para as 3 viagens com maior tempo decorrido:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca9ac6a-46ad-490c-9130-52c6ba77fbfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.nlargest(4, 'elapsed_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96e92d56-3756-4794-8cff-756ff4b9cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.nsmallest(4, 'total_amount')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb6ddb4-5c23-42b2-848c-ba296764b343",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## <font color='blue'>Trabalhando com índices</font>\n",
    "\n",
    "Até agora, não trabalhamos realmente com índices porque eles são apenas os números de linhas; entretanto, podemos alterar os valores que temos no índice para acessar recursos adicionais da biblioteca pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1d41e6-7815-4811-b7d6-1718afd3230b",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Setando e ordenando índices\n",
    "\n",
    "Atualmente, temos um RangeIndex, mas podemos mudar para um DatetimeIndex especificando uma coluna de data e hora ao chamar set_index():"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03135def-a358-49eb-98d6-e82a35a7ea38",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = taxis.set_index('pickup')\n",
    "taxis.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350656c9-6ed5-40d1-ad41-960c7dc4bea4",
   "metadata": {},
   "source": [
    "_Obs:_ Neste modo, após colocarmos uma coluna como linha, ela não volta a ser coluna depois.\n",
    "\n",
    "Como temos uma amostra do conjunto de dados completo, vamos classificar o índice por __ordem de horário de coleta__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebe4863e-feb2-4852-9c0a-7ab82e843fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = taxis.sort_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8f07f8-a109-4377-9974-8fe8cd5a3002",
   "metadata": {},
   "source": [
    "Agora podemos selecionar intervalos de nossos dados com base na data e hora da mesma forma que fizemos com os números das linhas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d07fb5bf-29af-4713-88dd-dc84310e0dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis['2019-10-23 07:45':'2019-10-23 08']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77975c81-2f20-4f3c-b9e1-59cb52479c8c",
   "metadata": {},
   "source": [
    "Quando nao especificamos o range, usamos o comando `loc[]:`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e649b913-d746-489a-9497-a415a42240ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis.loc['2019-10-23 08']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6270051-cd95-4a07-92a1-7da284b64ac7",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Resetando os índices\n",
    "\n",
    "Iremos estar trabalhando com time series depois desta seção, porém, as vezes queremos resetar nosso índice para números de linhas e recolocar as colunas novamente. Podemos fazer isso utilizando o comando `reset_index()`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7dba85-cc02-46e0-8bf4-ce4d9bf03a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxis = taxis.reset_index()\n",
    "taxis.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ddaa0b5-0381-49ab-af2a-4601339370dc",
   "metadata": {},
   "source": [
    "\n",
    "## <font color='blue'>Dados remodelados</font>\n",
    "\n",
    "O taxi dataset que estamos trabalhando está em um formato propício para uma análise. Mas isto não é sempre o caso. Vamos agora ver o TSA traveler throughput data, no qual compara as taxas de transferencia de 2021 em um mesmo dia para os anos de 2020 e 2019:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c10719b-c40c-4c4a-893b-b1b95e8fb687",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa = pd.read_csv('/home/nicolas.fs/Estudos-PIBE/Repositório-GIT/pandas-workshop/data/tsa_passenger_throughput.csv', parse_dates=['Date'])\n",
    "tsa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "246ba2a9-4fc6-4fdf-83c5-bd6add6c8747",
   "metadata": {},
   "source": [
    "Agora iremos renomear as colunas para poder trabalhar com a remodelagem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dde2cc-5e9b-4957-b6d3-d527a56e2563",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa = tsa.rename(columns=lambda x: x.lower().split()[0])\n",
    "tsa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54145d83-1567-4a57-a083-f140de019363",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Melting\n",
    "\n",
    "Melting nos ajuda a converter os dados em um formato longo, podendo ter todos os dados de taxas de transferência do viajante em uma única coluna em linhas diferentes para cada ano:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4646b33e-2154-4c8b-886c-d6a15a7c43aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted = tsa.melt(\n",
    "    id_vars='date', # column that uniquely identifies a row (can be multiple)\n",
    "    var_name='year', # name for the new column created by melting\n",
    "    value_name='travelers' # name for new column containing values from melted columns\n",
    ")\n",
    "tsa_melted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29813cc8-7108-4fe5-9cb5-52a8bef2d60c",
   "metadata": {},
   "source": [
    "_Obs:_ Podemos usar o comando `.sample(n)` caso queiramos em uma ordem aleatória.\n",
    "\n",
    "Basicamente isso fez com que agora tenhamos mais linhas, pois temos o número de viajantes relacionados a cada ano para cada data, ao invés de várias colunas referente a cada ano para a data específica em uma só linha."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43587aa3-d148-45ad-9db3-523a3650b4c0",
   "metadata": {},
   "source": [
    "Para converter isso em uma série temporal de produtividade de viajantes, precisamos substituir o ano na __coluna de data__ pelo ano na __coluna de ano__. Caso contrário, estaremos marcando os números dos anos anteriores com o ano errado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae3e665-7ff9-42fd-bf87-fdbb86c41d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted = tsa_melted.assign(\n",
    "    date=lambda x: pd.to_datetime(x.year + x.date.dt.strftime('-%m-%d'))\n",
    ")\n",
    "tsa_melted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfef4124-9f11-4d34-bbc1-049651ff77ed",
   "metadata": {},
   "source": [
    "Isso nos leva a alguns __valores nulos__:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f039bd-0b26-4d3f-a455-9c641db45935",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted.sort_values('date').tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953f3fc3-703e-464e-a3cf-91f76079d8a1",
   "metadata": {},
   "source": [
    "Eles podem ser retirados utilizando o método `dropna()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e77afa8-a0f7-477a-82c3-e63c52a0e041",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted = tsa_melted.dropna()\n",
    "tsa_melted.sort_values('date').tail(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd39283a-6966-4ad8-8041-7c0d73c40ffb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Pivô\n",
    "\n",
    "Usando o melted data, podemos pivotar os dados para compará-los em dias específicos durantes os diferentes anos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a9aa16-d12f-4f3b-b2d3-b2ef87ab4032",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_pivoted = tsa_melted\\\n",
    "    .query('date.dt.month == 3 and date.dt.day <= 10')\\\n",
    "    .assign(day_in_march=lambda x: x.date.dt.day)\\\n",
    "    .pivot(index='year', columns='day_in_march', values='travelers')\n",
    "tsa_pivoted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "295bf07c-0b7f-4052-b302-c7853545c948",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Transposição\n",
    "\n",
    "O atributo de transposição `T` prove uma maneira rapida de inverter linhas e colunas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c21229-3b36-4583-a52c-d23f7f23d504",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_pivoted.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bb23304-6f17-44cd-94ce-33c1dfc695e8",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Mesclando\n",
    "\n",
    "Tipicamente observamos mudanças em viagens aéreas durantes os feriados, então podemos adicionar mais informações sobre as datas em nosso dataset provendo um maior contexto. O arquivo __holidays.csv__ contém alguns feriados importantes nos Estados Unidos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93e371a3-8016-481b-9c2b-740ce2e3de1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "holidays = pd.read_csv('/home/nicolas.fs/Estudos-PIBE/Repositório-GIT/pandas-workshop/data/holidays.csv', parse_dates=True, index_col='date')\n",
    "holidays.loc['2019']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b0e147-302b-4dba-a5de-3ab4be9ebaeb",
   "metadata": {},
   "source": [
    "Podemos agora mesclar os feriados com o dataset de viagens providenciando mais informação para nossa análise:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd815405-a82c-49f2-80c2-6382a3958635",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holidays = tsa_melted\\\n",
    "    .merge(holidays, left_on='date', right_index=True, how='left')\\\n",
    "    \n",
    "tsa_melted_holidays.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f4344b1-306e-4e93-9360-beabfc682d49",
   "metadata": {},
   "source": [
    "Podemos agora procurar estes feriados pelos índices ou pelas datas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aedc399-1f2f-441c-bce3-eedd0230dd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = tsa_melted_holidays.loc[[863]]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37fbf43-2923-4f7e-8fc3-5433cd9de5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_to_find = '2019-07-04'\n",
    "result = tsa_melted_holidays.loc[tsa_melted_holidays['date'] == date_to_find]\n",
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e0da56-640d-461d-959f-7b912bcd5b9b",
   "metadata": {},
   "source": [
    "_Obs:_ Quando você usa um único par de colchetes `[]` com `.loc` ou `.iloc`, o resultado é uma Série __(pd.Series)__ se você está selecionando uma única linha ou coluna.\n",
    "\n",
    "_Obs:_ Quando você usa um duplo par de colchetes `[[]]`, você está criando uma lista de rótulos (mesmo que seja um único rótulo) e isso garante que o resultado seja um DataFrame __(pd.DataFrame)__, não importa quantas linhas ou colunas você esteja selecionando."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a639146a-49dd-49b7-9cbd-3e2223f18170",
   "metadata": {},
   "source": [
    "Podemos dar um passo adiante, marcando alguns dias antes e depois de cada feriado como parte do feriado. Isso tornaria mais fácil comparar as viagens de férias ao longo dos anos e procurar qualquer aumento nas viagens durante os feriados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df840e7-6342-41aa-9beb-876c5558d5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel = tsa_melted_holidays.assign(\n",
    "    holiday=lambda x:\n",
    "        x.holiday\\\n",
    "            .fillna(method='ffill', limit=1)\\\n",
    "            .fillna(method='bfill', limit=2)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e8efba6-8ffb-42ff-a7be-00ba10e1d490",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.query(\n",
    "    'year == \"2019\" and '\n",
    "    '(holiday == \"Thanksgiving\" or holiday.str.contains(\"Christmas\"))'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ad66a8-47b2-498c-b2c7-35eef6f7823c",
   "metadata": {},
   "source": [
    "\n",
    "## <font color='blue'>Agrupamentos e agregações</font>\n",
    "\n",
    "Após reformatar e limpar nossos dados, podemos fazer agregações para resumi-los de várias maneiras. Nesta seção, iremos explorar isso utilizando tabelas dinâmicas, crosstabs, e agrupamentos por operações para agregar os dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dfe11b-77c0-46ff-820a-801ebf5eafe0",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Tabelas dinâmicas\n",
    "\n",
    "Podemos construir uma tabela dinâmica para comparar as viagens de feriado durante os anos em nosso dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c144667-8769-44eb-a4af-ad4f51e7fd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.pivot_table(\n",
    "    index='year', columns='holiday', \n",
    "    values='travelers', aggfunc='sum'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8657db-4b60-4ed7-8f60-20a03024a30d",
   "metadata": {},
   "source": [
    "Os valores `NaN` na tabela dinâmica ocorrem porque __não há dados__ disponíveis para esses feriados em certos anos. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d044ae3-0fa3-4dab-8975-8f572be33f59",
   "metadata": {},
   "source": [
    "Podemos usar o comando `pct_change()` neste resultado para ver quais períodos de viagens de férias tiveram a maior mudança nas viagens, ou seja, o comando é uma função que calcula a mudança percentual entre os __elementos consecutivos__ ao longo de uma determinada dimensão do DataFrame.\n",
    "\n",
    "__Primeiro, um exemplo prático para entender:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a568c5-9e64-4207-9047-78fa5eb5e3af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Exemplo de dados\n",
    "data = {\n",
    "    'day': ['2024-01-01', '2024-01-02', '2024-01-03', '2024-01-04'],\n",
    "    'travelers': [1000, 1100, 1050, 1150]\n",
    "}\n",
    "df = pd.DataFrame(data)\n",
    "df['day'] = pd.to_datetime(df['day'])\n",
    "df.set_index('day', inplace=True)\n",
    "\n",
    "# Calculando a mudança percentual\n",
    "df['pct_change'] = df['travelers'].pct_change()\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fbb90bf-6c2e-4b98-9129-d61229e6cda1",
   "metadata": {},
   "source": [
    "Cálculos Detalhados\n",
    "\n",
    "_2024-01-01: Não há valor anterior, então o resultado é NaN._\n",
    "\n",
    "_2024-01-02: (1100-1000)/1000_\n",
    "\n",
    "_2024-01-03: (1050-1100)/1100_\n",
    "\n",
    "_2024-01-04: (1150-1050)/1050_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dcfeec5-1a0a-41fe-89c7-e49df8e4f4f4",
   "metadata": {},
   "source": [
    "__Agora, vamos utilizar o DataFrame que possuímos para fazer nossas análises:__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2634d667-b451-4b95-840f-5c236bda84b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.pivot_table(\n",
    "    index='year', columns='holiday', \n",
    "    values='travelers', aggfunc='sum'\n",
    ").pct_change()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38ebe94e-7c89-497e-9e71-41c8bd5e1d07",
   "metadata": {},
   "source": [
    "Vamos fazer uma última tabela dinâmica com subtotais de colunas e linhas, junto com algumas melhorias de formatação. Primeiro, definimos uma opção de exibição para todos os carros alegóricos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89466ab-fe76-46e9-816e-b51687362c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.float_format', '{:,.0f}'.format)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5337064a-60f7-4f06-bb7c-aa41e7913323",
   "metadata": {},
   "source": [
    "A seguir, agrupamos a véspera de Natal e o dia do Natal, e da mesma forma para a véspera e o dia do Ano Novo, e criamos a tabela dinâmica:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ca70fe-f1fb-40bf-bf8c-027b41900104",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "tsa_melted_holiday_travel.assign(\n",
    "    holiday=lambda x: np.where(\n",
    "        x.holiday.str.contains('Christmas|New Year', regex=True), \n",
    "        x.holiday.str.replace('Day|Eve', '', regex=True).str.strip(), \n",
    "        x.holiday\n",
    "    )\n",
    ").pivot_table(\n",
    "    index='year', columns='holiday', \n",
    "    values='travelers', aggfunc='sum', \n",
    "    margins=True, margins_name='Total'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b79e17f-90b3-4046-a559-1b4f73837cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reset para prosseguir\n",
    "\n",
    "pd.reset_option('display.float_format')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d39d350-1aad-47fc-9e8a-5bbe6cdaaab4",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### Crosstabs\n",
    "\n",
    "O comando `pd.crosstab()` nos da uma maneira fácil de criar uma tabela de frequência. Aqui, contamos o número de dias de viagem de baixo, médio e alto volume por ano, usando a função `pd.cut()` para criar três compartimentos de volume de viagem de largura igual:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81526bc1-dd55-4e2d-bd8c-d5bc8dab1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(\n",
    "    index=pd.cut(\n",
    "        tsa_melted_holiday_travel.travelers, \n",
    "        bins=3, labels=['low', 'medium', 'high']\n",
    "    ),\n",
    "    columns=tsa_melted_holiday_travel.year,\n",
    "    rownames=['travel_volume']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c4d549-15aa-4a55-ba0f-4d3064b3aaf5",
   "metadata": {},
   "source": [
    "Podemos notar que o comando `pd.crosstab()` suporta outras agregações, desde que você passe os dados para agregar como valores e especifique a agregação com `aggfunc`. Podemos também adicionar subtotais e normalizar os dados.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f809e78f-b8e8-4c9a-80ba-a0edc5115a0e",
   "metadata": {},
   "source": [
    "### Grupo por operações\n",
    "\n",
    "Ao invés de ter agrupamentos utilizando `mean()` ou `describe()` em nosso dataset tudo de uma vez, podemos realizar estes cálculos __por grupo__ primeiro chamando o comando `groupby()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97961584-8497-4c68-956b-7a7c39fb882c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.groupby('year').describe(include=np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fdffae7-f017-46a9-9d74-59e90f1b1a7e",
   "metadata": {},
   "source": [
    "Exemplo utilizando o método `describe()` anteriormente citado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d9a2815-b863-4fc3-9fe8-3cedf270b74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.describe(include=np.number)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97a21fe-e25a-4a8d-b4a3-994ea27f4c2d",
   "metadata": {},
   "source": [
    "Podemos perceber que se somarmos todos os os valores em cada coluna no primeiro exemplo que estão separados por agrupamentos dos anos, irá dar o mesmo valor que temos referente a cada linha do segundo exemplo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a012171-ee90-402d-b4a3-a323cfca6723",
   "metadata": {},
   "source": [
    "Os grupos também podem ser usados para realizar cálculos separados por subconjunto de dados. Por exemplo, podemos __encontrar os dias de viagem com maior e menor volume por ano__ usando `rank()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5dba80-808e-4052-985d-169f12247402",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel_ranked = tsa_melted_holiday_travel.assign(\n",
    "    travel_volume_rank=lambda x: x.groupby('year').travelers.rank(ascending=False)\n",
    ").sort_values(['travel_volume_rank', 'year'])\n",
    "\n",
    "tsa_melted_holiday_travel_ranked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6484956-f823-4743-854b-f710a5249bb6",
   "metadata": {},
   "source": [
    "Para saber outros rankings podemos definir o __range__ do nosso row de dados:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43ed4a0-28ee-4877-8d34-3908e6793d8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel_ranked[96:99]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0244c207-7d1a-4c18-a548-8c2124ca9433",
   "metadata": {},
   "source": [
    "Os exemplos de grupo anteriores chamaram um único método nos dados agrupados, mas usando o método `agg()` podemos especificar qualquer número deles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06aecf6-d3ff-4ea0-bf63-a547689e8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsa_melted_holiday_travel.assign(\n",
    "    holiday_travelers=lambda x: np.where(~x.holiday.isna(), x.travelers, np.nan),\n",
    "    non_holiday_travelers=lambda x: np.where(x.holiday.isna(), x.travelers, np.nan),\n",
    "    year=lambda x: pd.to_numeric(x.year)\n",
    ").select_dtypes(include='number').groupby('year').agg(['mean', 'std'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebb67fd-1ee5-4030-a3d9-0a6f9e6c99b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Além disso, podemos especificar quais agregações realizar em cada coluna:\n",
    "\n",
    "tsa_melted_holiday_travel.assign(\n",
    "    holiday_travelers=lambda x: np.where(~x.holiday.isna(), x.travelers, np.nan),\n",
    "    non_holiday_travelers=lambda x: np.where(x.holiday.isna(), x.travelers, np.nan)\n",
    ").groupby('year').agg({\n",
    "    'holiday_travelers': ['mean', 'std'], \n",
    "    'holiday': ['nunique', 'count']\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb1b3581-04c9-424b-a942-40cfa98ba6fd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
